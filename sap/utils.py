from common.html_parser import HTMLParser
from common.json_writer import JSONWriter
from sap.row_parser import RowParser
from common.utils import dump_as_json
from datetime import datetime


def get_publish_date_string(parser):
    date_para = parser.get_tag_by_id("main-content")
    p_soup = date_para.find_all("p")
    p_text = p_soup[1].text
    p_text = p_text.split(",", 2)[0]    
    return p_text

def get_outer_div(parser, div_class):
    div = parser.get_tag_by_class(div_class)
    return div 

def get_title(parser):
    title_soup = parser.get_tag_by_id("title-text")
    title = title_soup.a.text.strip()
    title = title.replace("\u00e2\u0080\u0093", "").replace("\u2013", "")
    return title

def get_security_alerts_json(vendor, urls,div_class):
    cves = list()
    for url in urls:
        parser = HTMLParser(url)

        title = get_title(parser)
        print(title)
        outer_div = get_outer_div(parser, div_class)
        alerts = parser.get_table_body_rows(outer_div)
        # alerts = [alerts[-2]]
        # alerts = [alerts[0],alerts[1],alerts[2],alerts[3], alerts[4], alerts[5], alerts[6]]
        # print(alerts)
        publisging_date = get_publish_date_string(parser)

        row_parser = RowParser(publisging_date)

        writer = JSONWriter(alerts, row_parser)
        cves += writer.parse_alerts(
            vendor, url, None, title)
 
    return dump_as_json(vendor,cves)

def get_publish_date(date_string):
    return datetime.strptime(date_string, "%B %Y") 

def should_parse_bulletin(text, from_date, to_date):
    date = get_publish_date(text)
    if date >= from_date and date <= to_date :
        return True
    return False

